{"nbformat_minor": 0, "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "version": "3.4.1", "pygments_lexer": "ipython3", "file_extension": ".py", "mimetype": "text/x-python", "nbconvert_exporter": "python"}}, "cells": [{"outputs": [{"metadata": {}, "output_type": "execute_result", "data": {"text/plain": "'C:\\\\Users\\\\cdron\\\\Desktop\\\\Cleanup\\\\Misc\\\\kaggle\\\\West_Nile_Virus_Pred'"}, "execution_count": 1}], "metadata": {"trusted": true, "collapsed": false}, "execution_count": 1, "cell_type": "code", "source": "import os\nos.chdir(r\"C:\\Users\\cdron\\Desktop\\Cleanup\\Misc\\kaggle\\West_Nile_Virus_Pred\")\nos.getcwd()"}, {"outputs": [], "metadata": {"trusted": true, "collapsed": true}, "execution_count": 2, "cell_type": "code", "source": "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport csv\nimport gzip\n\nimport numpy as np\nimport pandas as pd\nfrom dateutil.parser import parse"}, {"outputs": [], "metadata": {"trusted": true, "collapsed": true}, "execution_count": 3, "cell_type": "code", "source": "WEATHER_VARS_WITH_M_T = (u'Tmax', u'Tmin', u'Tavg', u'Depart', u'DewPoint',\n                         u'WetBulb', u'Heat', u'Cool', u'Snowfall',\n                         u'PrecipTotal', u'StnPressure', u'SeaLevel',\n                         u'ResultSpeed', u'ResultDir', u'AvgSpeed', u'Water1')\n\nWEATHER_PHENOMENA = ('BCFG', 'BLDU', 'BLSN', 'BR', 'DU', 'DZ', 'FG', 'FG+',\n                     'FU', 'FZDZ', 'FZFG', 'FZRA', 'GR', 'GS', 'HZ', 'MIFG',\n                     'PL', 'PRFG', 'RA', 'SG', 'SN', 'SQ', 'TS', 'TSRA',\n                     'TSSN', 'UP', 'VCFG', 'VCTS')"}, {"outputs": [], "metadata": {"trusted": true, "collapsed": true}, "execution_count": 4, "cell_type": "code", "source": "def haversine_distance(lat1, lon1, lat2, lon2):\n    r_earth = 6371.\n    dlat = np.abs(lat1-lat2)*np.pi/180.\n    dlon = np.abs(lon1-lon2)*np.pi/180.\n    lat1 *= np.pi/180.\n    lat2 *= np.pi/180.\n    dist = 2. * r_earth * np.arcsin(\n                            np.sqrt(\n                                np.sin(dlat/2.)**2 +\n                                    np.cos(lat1) * np.cos(lat2) *\n                                    np.sin(dlon/2.)**2))\n    return dist"}, {"outputs": [], "metadata": {"trusted": true, "collapsed": true}, "execution_count": 6, "cell_type": "code", "source": "def lat_lon_box(lat, lon, dist):\n    r_earth = 6371.\n    d_2r = dist/(2.*r_earth)\n    dlat = 2. * (d_2r)\n    dlon = 2. * np.arcsin((np.sin(d_2r))/(np.cos(lat)))\n    dlat *= 180./np.pi\n    dlon *= 180./np.pi\n    return abs(dlat), abs(dlon) "}, {"outputs": [], "metadata": {"trusted": true, "collapsed": false}, "execution_count": 13, "cell_type": "code", "source": "def feature_extraction():\n    spray_df = pd.read_csv('spray.csv')\n\n    spray_lat_lon_list = []\n    for idx, row in spray_df.iterrows():\n        spray_lat_lon_list.append((row['Latitude'], row['Longitude']))\n\n    weather_features = []\n    cumu_labels = ('Tmax', 'Tmin', 'PrecipTotal')\n    cumu_features = {}\n    cumu_total = 0\n    current_year = -1\n    with open('weather.csv', 'rt') as wfile:\n        wcsv = csv.reader(wfile, delimiter=',')\n        weather_labels = next(wcsv)\n        for row in wcsv:\n            rowdict = dict(zip(weather_labels, row))\n            rowdict['Date'] = parse(rowdict['Date'])\n            current_date = rowdict['Date']\n            if current_date.year != current_year:\n                current_year = current_date.year\n                cumu_features = {k: 0 for k in cumu_labels}\n                cumu_total = 0\n            for k in WEATHER_VARS_WITH_M_T:\n                if k in rowdict:\n                    rowdict[k] = rowdict[k].replace('M', 'nan')\n                    rowdict[k] = rowdict[k].replace('T', '0.0')\n            for k in rowdict:\n                if rowdict[k] == '-':\n                    rowdict[k] = 'nan'\n                if type(rowdict[k]) == str:\n                    rowdict[k] = rowdict[k].strip()\n            for ph in WEATHER_PHENOMENA:\n                rowdict['wp%s' % ph] = '0'\n            for ph in rowdict['CodeSum'].split():\n                if ph in WEATHER_PHENOMENA:\n                    rowdict['wp%s' % ph] = '1'\n            for lab in cumu_labels:\n                _tmp = float(rowdict[lab])\n                if not np.isnan(_tmp):\n                    cumu_features[lab] += _tmp\n            cumu_total += 1\n            for lab in ('Tmax', 'Tmin', 'PrecipTotal'):\n                rowdict['%s_cumu' % lab] = cumu_features[lab] / cumu_total\n            weather_features.append(rowdict)\n#            print('\\n'.join(['%s: %s' % (k, rowdict[k]) for k in rowdict]))\n#            exit(0)\n    for ph in WEATHER_PHENOMENA:\n        weather_labels.append('wp%s' % ph)\n    for lab in cumu_labels:\n        weather_labels.append('%s_cumu' % lab)\n\n\n    for prefix in 'train', 'test':\n        with open('%s.csv' % prefix, 'rt') as csvfile:\n            outfile = open('%s_full.csv' % prefix, 'w', newline='')\n            csv_reader = csv.reader(csvfile)\n            labels = next(csv_reader)\n\n            out_labels = labels +\\\n                         ['n_spray_%d' % x for x in range(1,11)]\n            for lab in weather_labels:\n                if lab == 'Date':\n                    continue\n                out_labels.append(lab)\n                csv_writer = csv.writer(outfile)\n            csv_writer.writerow(out_labels)\n\n            for idx, row in enumerate(csv_reader):\n                if idx % 1000 == 0:\n                    print('processed %d' % idx)\n#                if idx > 100:\n#                    exit(0)\n                row_dict = dict(zip(labels, row))\n\n                current_date = parse(row_dict['Date'])\n                cur_lat = float(row_dict['Latitude'])\n                cur_lon = float(row_dict['Longitude'])\n\n                for idx in range(1, 11):\n                    row_dict['n_spray_%d' % idx] = 0\n                dlat, dlon = lat_lon_box(cur_lat, cur_lon, 1.5)\n                for slat, slon in spray_lat_lon_list:\n#                    print(dlat, dlon, abs(slat-cur_lat), abs(slon-cur_lon))\n                    if abs(slat-cur_lat) > dlat or abs(slon-cur_lon) > dlon:\n                        continue\n                    sdist = haversine_distance(cur_lat, cur_lon, slat, slon)\n                    for idx in range(1,11):\n                        if sdist < idx/10.0:\n                            row_dict['n_spray_%d' % idx] += 1\n\n                for lab in ['Tmax_cumu', 'Tmin_cumu', 'PrecipTotal_cumu']:\n                    row_dict[lab] = 0\n                most_recent = 1000000\n                most_recent_w = weather_features[0]\n                for wfeat in weather_features:\n                    wdate = wfeat['Date']\n                    if current_date.year != wdate.year:\n                        continue\n                    wdur = abs((current_date - wdate).days)\n                    if wdur < most_recent:\n                        most_recent = wdur\n                        most_recent_w = wfeat\n                for lab in weather_labels:\n                    if lab == 'Date':\n                        continue\n                    row_dict[lab] = most_recent_w[lab]\n                row_val = [row_dict[col] for col in out_labels]\n                csv_writer.writerow(row_val)\n#                outfile.flush()\n#                print('\\n'.join(['%s: %s' % (k, row_dict[k]) for k in row_dict]))\n#                exit(0)\n    return"}, {"outputs": [{"text": "processed 0\nprocessed 1000\nprocessed 2000\nprocessed 3000\nprocessed 4000\nprocessed 5000\nprocessed 6000\nprocessed 7000\nprocessed 8000\nprocessed 9000\nprocessed 10000\nprocessed 0\nprocessed 1000\nprocessed 2000\nprocessed 3000\nprocessed 4000\nprocessed 5000\nprocessed 6000\nprocessed 7000\nprocessed 8000\nprocessed 9000\nprocessed 10000\nprocessed 11000\nprocessed 12000\nprocessed 13000\nprocessed 14000\nprocessed 15000\nprocessed 16000\nprocessed 17000\nprocessed 18000\nprocessed 19000\nprocessed 20000\nprocessed 21000\nprocessed 22000\nprocessed 23000\nprocessed 24000\nprocessed 25000\nprocessed 26000\nprocessed 27000\nprocessed 28000\nprocessed 29000\nprocessed 30000\nprocessed 31000\nprocessed 32000\nprocessed 33000\nprocessed 34000\nprocessed 35000\nprocessed 36000\nprocessed 37000\nprocessed 38000\nprocessed 39000\nprocessed 40000\nprocessed 41000\nprocessed 42000\nprocessed 43000\nprocessed 44000\nprocessed 45000\nprocessed 46000\nprocessed 47000\nprocessed 48000\nprocessed 49000\nprocessed 50000\nprocessed 51000\nprocessed 52000\nprocessed 53000\nprocessed 54000\nprocessed 55000\nprocessed 56000\nprocessed 57000\nprocessed 58000\nprocessed 59000\nprocessed 60000\nprocessed 61000\nprocessed 62000\nprocessed 63000\nprocessed 64000\nprocessed 65000\nprocessed 66000\nprocessed 67000\nprocessed 68000\nprocessed 69000\nprocessed 70000\nprocessed 71000\nprocessed 72000\nprocessed 73000\nprocessed 74000\nprocessed 75000\nprocessed 76000\nprocessed 77000\nprocessed 78000\nprocessed 79000\nprocessed 80000\nprocessed 81000\nprocessed 82000\nprocessed 83000\nprocessed 84000\nprocessed 85000\nprocessed 86000\nprocessed 87000\nprocessed 88000\nprocessed 89000\nprocessed 90000\nprocessed 91000\nprocessed 92000\nprocessed 93000\nprocessed 94000\nprocessed 95000\nprocessed 96000\nprocessed 97000\nprocessed 98000\nprocessed 99000\nprocessed 100000\nprocessed 101000\nprocessed 102000\nprocessed 103000\nprocessed 104000\nprocessed 105000\nprocessed 106000\nprocessed 107000\nprocessed 108000\nprocessed 109000\nprocessed 110000\nprocessed 111000\nprocessed 112000\nprocessed 113000\nprocessed 114000\nprocessed 115000\nprocessed 116000\n", "name": "stdout", "output_type": "stream"}], "metadata": {"trusted": true, "collapsed": false}, "execution_count": 14, "cell_type": "code", "source": "if __name__ == '__main__':\n    feature_extraction()"}, {"outputs": [], "metadata": {"trusted": true, "collapsed": true}, "execution_count": 7, "cell_type": "code", "source": "SPECIES = ['CULEX ERRATICUS', 'CULEX PIPIENS', 'CULEX PIPIENS/RESTUANS',\n           'CULEX RESTUANS', 'CULEX SALINARIUS', 'CULEX TARSALIS',\n           'CULEX TERRITANS']"}, {"outputs": [], "metadata": {"trusted": true, "collapsed": true}, "execution_count": 8, "cell_type": "code", "source": "def clean_data(df):\n    df['Species'] = df['Species'].map({k: n for (n, k) in enumerate(SPECIES)})\n    n_null = (df['Species'].isnull()).sum()\n    nan_species = np.random.random_integers(0, len(SPECIES)-1, size=(n_null,))\n    if n_null > 0:\n        df.loc[df['Species'].isnull(), 'Species'] = nan_species\n\n    df['is_sat_trap'] = df['Trap'].apply(lambda x: len(x[4:]) > 0).astype(int)\n    df['Trap'] = df['Trap'].apply(lambda x: x[1:4]).astype(int)\n\n    df = df.drop(labels=['Date', 'Address', 'Street',\n                         'AddressNumberAndStreet', 'CodeSum', 'SnowFall',\n                         'Water1', 'Station', 'Depth', 'wpBCFG', 'wpBLDU',\n                         'wpBLSN', 'wpDU', 'wpFG+', 'wpFU', 'wpFZDZ',\n                         'wpFZFG', 'wpFZRA', 'wpGR', 'wpGS', 'wpMIFG', 'wpPL',\n                         'wpPRFG', 'wpSG', 'wpSN', 'wpSQ', 'wpTSSN', 'wpUP',\n                         'wpVCFG', 'AddressAccuracy', 'WetBulb', \n                         'StnPressure', 'Latitude', 'Longitude'], axis=1)\n    return df"}, {"outputs": [], "metadata": {"trusted": true, "collapsed": true}, "execution_count": 9, "cell_type": "code", "source": "def load_data(do_plots=False):\n    train_df = pd.read_csv('train_full.csv')\n    test_df = pd.read_csv('test_full.csv')\n    submit_df = pd.read_csv('sampleSubmission.csv')\n\n    train_df = clean_data(train_df)\n    test_df = clean_data(test_df)\n\n    print(submit_df.dtypes)\n\n    for col in test_df.columns:\n        if (test_df[col].isnull()).sum() > 0:\n            print(col, test_df[col].dtype)\n#    print(sorted(train_df['is_sat_trap'].unique()))\n#    print(sorted(test_df['Species'].unique()))\n    if do_plots:\n        from plot_data import plot_data\n        plot_data(train_df, prefix='train_html')\n        plot_data(test_df, prefix='test_html')\n\n    features = train_df.drop(labels=['NumMosquitos', 'WnvPresent'],\n                           axis=1).columns\n\n    xtrain = train_df.drop(labels=['NumMosquitos', 'WnvPresent'],\n                           axis=1).values\n    ytrain = train_df[['NumMosquitos', 'WnvPresent']].values\n    xtest = test_df.drop(labels=['Id'], axis=1).values\n    ytest = submit_df\n    return xtrain, ytrain, xtest, ytest, features"}, {"outputs": [{"text": "C:\\Anaconda3 2.1.0\\lib\\site-packages\\pandas\\io\\parsers.py:1159: DtypeWarning: Columns (36) have mixed types. Specify dtype option on import or set low_memory=False.\n  data = self._reader.read(nrows)\nC:\\Anaconda3 2.1.0\\lib\\site-packages\\pandas\\io\\parsers.py:1159: DtypeWarning: Columns (35) have mixed types. Specify dtype option on import or set low_memory=False.\n  data = self._reader.read(nrows)\n", "name": "stderr", "output_type": "stream"}, {"text": "Id            int64\nWnvPresent    int64\ndtype: object\n[(10506, 39), (10506, 2), (116293, 39), (116293, 2)]\n", "name": "stdout", "output_type": "stream"}], "metadata": {"trusted": true, "collapsed": false}, "execution_count": 10, "cell_type": "code", "source": "if __name__ == '__main__':\n    xtrain, ytrain, xtest, ytest, features = load_data(do_plots=False)\n    print([df.shape for df in (xtrain, ytrain, xtest, ytest)])"}, {"outputs": [], "metadata": {"trusted": true, "collapsed": true}, "execution_count": 11, "cell_type": "code", "source": "import numpy as np\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier,\\\n                             GradientBoostingRegressor, \\\n                             GradientBoostingClassifier\nfrom sklearn.cross_validation import train_test_split\n#from sklearn.metrics.roc_curve\nfrom sklearn.metrics import roc_auc_score, mean_squared_error\nfrom sklearn.grid_search import GridSearchCV"}, {"outputs": [], "metadata": {"trusted": true, "collapsed": true}, "execution_count": 22, "cell_type": "code", "source": "def transform_to_log(y):\n    #return np.log1p(y)\n    return np.sqrt(3/8+y)"}, {"outputs": [], "metadata": {"trusted": true, "collapsed": true}, "execution_count": 23, "cell_type": "code", "source": "def transform_from_log(ly):\n    #return np.round(np.expm1(ly)).astype(int)\n    return np.round(np.square(ly)-3/8).astype(int)"}, {"outputs": [], "metadata": {"trusted": true, "collapsed": true}, "execution_count": 24, "cell_type": "code", "source": "def scorer(estimator, X, y):\n    ypred = estimator.predict_proba(X)\n    return 1.0/roc_auc_score(y, ypred[:, 1])"}, {"outputs": [], "metadata": {"trusted": true, "collapsed": true}, "execution_count": 25, "cell_type": "code", "source": "def train_nmosq_model(model, xtrain, ytrain, do_grid_search=False):\n    xTrain, xTest, yTrain, yTest = train_test_split(xtrain,\n                                                    ytrain[:,0],\n                                                    test_size=0.5)\n    n_est = [10, 20]\n    m_dep = [2, 3, 4, 5, 6, 7, 10]\n\n    if do_grid_search:\n        model = GridSearchCV(estimator=model,\n                                    param_grid=dict(n_estimators=n_est,\n                                                    max_depth=m_dep),\n                                    scoring=scorer,\n                                    n_jobs=-1, verbose=1)\n    model.fit(xTrain, yTrain)\n    print(model.score(xTest, yTest))\n    if hasattr(model, 'best_params_'):\n        print(model.best_params_)"}, {"outputs": [], "metadata": {"trusted": true, "collapsed": true}, "execution_count": 18, "cell_type": "code", "source": "def train_has_wnv_model(model, xtrain, ytrain, do_grid_search=False,\n                        feature_list=None):\n    xTrain, xTest, yTrain, yTest = train_test_split(xtrain,\n                                                    ytrain[:,1],\n                                                    test_size=0.5)\n    n_est = [10, 20]\n    m_dep = [2, 3, 4, 5, 6, 7, 10]\n\n    if do_grid_search:\n        model = GridSearchCV(estimator=model,\n                                    param_grid=dict(n_estimators=n_est,\n                                                    max_depth=m_dep),\n                                    scoring=scorer,\n                                    n_jobs=-1, verbose=1)\n    model.fit(xTrain, yTrain)\n    ypred = model.predict_proba(xTest)\n    print(roc_auc_score(yTest, ypred[:, 1]))\n    if hasattr(model, 'best_params_'):\n        print(model.best_params_)\n    if hasattr(model, 'feature_importances_') and feature_list is not None:\n        print('\\n'.join(['%s: %s' % (k, v) for (k,v) in sorted(zip(feature_list, \n               model.feature_importances_), key=lambda x: x[1])]))\n    return"}, {"outputs": [], "metadata": {"trusted": true, "collapsed": true}, "execution_count": 33, "cell_type": "code", "source": "def prepare_submission(model, xtrain, ytrain, xtest, ytest, feature_list=None):\n    model.fit(xtrain, ytrain)\n    if hasattr(model, 'feature_importances_') and feature_list is not None:\n        print('\\n'.join(['%s: %s' % (k, v) for (k,v) in sorted(zip(feature_list, \n               model.feature_importances_), key=lambda x: x[1])]))\n    ypred = model.predict_proba(xtest)\n    ytest.loc[:, 'WnvPresent'] = ypred[:, 1]\n    ytest['Id'] = ytest['Id'].astype(int)\n    ytest.to_csv('k_jun3_1.csv', index=False)"}, {"outputs": [], "metadata": {"trusted": true, "collapsed": false}, "execution_count": 39, "cell_type": "code", "source": "np.random.seed(16809)\ndef my_model():\n    xtrain, ytrain, xtest, ytest, features = load_data()\n\n#    ytrain = transform_to_log(ytrain)\n#\n#    mosq_model = GradientBoostingRegressor(loss='ls', verbose=1, max_depth=7,\n#                                        n_estimators=20)\n#    train_nmosq_model(mosq_model, xtrain, ytrain, do_grid_search=False)\n\n    model = GradientBoostingClassifier(verbose=1, max_depth=3, learning_rate=0.0975,\n                                       n_estimators=200)\n    print(model)\n\n    train_has_wnv_model(model, xtrain, ytrain, do_grid_search=False, \n                        feature_list=features)\n\n    prepare_submission(model, xtrain, ytrain[:, 1], xtest, ytest, \n                       feature_list=features)\n    \n\n    return"}, {"outputs": [{"text": "Id            int64\nWnvPresent    int64\ndtype: object\nGradientBoostingClassifier(init=None, learning_rate=0.0975, loss='deviance',\n              max_depth=3, max_features=None, max_leaf_nodes=None,\n              min_samples_leaf=1, min_samples_split=2, n_estimators=200,\n              random_state=None, subsample=1.0, verbose=1,\n              warm_start=False)\n      Iter       Train Loss   Remaining Time \n         1           0.4071            6.29s\n         2           0.3969            4.42s\n         3           0.3888            3.95s\n         4           0.3810            4.16s\n         5           0.3734            3.81s\n         6           0.3683            3.67s\n         7           0.3631            3.83s\n         8           0.3590            3.46s\n         9           0.3558            3.39s\n        10           0.3523            3.63s\n        20           0.3306            3.16s\n        30           0.3170            2.86s\n        40           0.3090            2.61s\n        50           0.3034            2.40s\n        60           0.2977            2.23s\n        70           0.2919            2.05s\n        80           0.2868            1.91s\n        90           0.2828            1.74s\n       100           0.2791            1.57s\n       200           0.2453            0.00s\n0.835827958734\nHeat: 0.0\nwpVCTS: 0.0\nwpDZ: 0.000547907588431\nwpHZ: 0.0011644076624\nwpRA: 0.00148584564741\nwpTSRA: 0.00148684469101\nwpBR: 0.00346071539613\nwpFG: 0.00461676452481\nTavg: 0.00496647144232\nPrecipTotal: 0.00800721133041\nCool: 0.0101205110797\nAvgSpeed: 0.0101277677693\nn_spray_8: 0.010377550709\nn_spray_4: 0.0116461356064\nn_spray_1: 0.0121499768238\nis_sat_trap: 0.0129606677286\nn_spray_6: 0.013623097878\nDepart: 0.0141525069407\nwpTS: 0.0146787296286\nn_spray_7: 0.0167302496699\nn_spray_9: 0.0177481661475\nTmax: 0.0183697664475\nn_spray_2: 0.0223853587421\nn_spray_3: 0.023320648876\nDewPoint: 0.0236262273244\nSunset: 0.0236825817498\nn_spray_5: 0.0253627685509\nSeaLevel: 0.0276597042341\nTmin: 0.0281806404893\nn_spray_10: 0.0372714687266\nPrecipTotal_cumu: 0.0383380591109\nResultSpeed: 0.0414385913704\nSunrise: 0.0447505337842\nTmin_cumu: 0.0509515615564\nResultDir: 0.0533830338117\nSpecies: 0.0536162889259\nTmax_cumu: 0.0539776143298\nBlock: 0.0614671216283\nTrap: 0.202166502077\n      Iter       Train Loss   Remaining Time \n         1           0.3987            9.31s\n         2           0.3891            6.18s\n         3           0.3814            6.44s\n         4           0.3740            5.57s\n         5           0.3685            5.73s\n         6           0.3628            5.25s\n         7           0.3581            5.45s\n         8           0.3544            5.15s\n         9           0.3511            5.22s\n        10           0.3482            5.01s\n        20           0.3291            4.50s\n        30           0.3197            4.24s\n        40           0.3133            3.92s\n        50           0.3094            3.64s\n        60           0.3057            3.34s\n        70           0.3026            3.09s\n        80           0.3001            2.82s\n        90           0.2978            2.60s\n       100           0.2954            2.36s\n       200           0.2750            0.00s\nHeat: 0.0\nwpDZ: 0.0\nwpRA: 0.0\nwpVCTS: 0.0\nwpHZ: 0.00072349116266\nwpBR: 0.00163415293868\nn_spray_7: 0.00316511077736\nwpTSRA: 0.00341127553861\nis_sat_trap: 0.00555767451171\nwpFG: 0.00576655785256\nPrecipTotal: 0.00638074232461\nn_spray_3: 0.00691334494953\nn_spray_6: 0.00729700426614\nTavg: 0.00766768429396\nn_spray_8: 0.00782447545895\nTmax: 0.00782559254891\nCool: 0.0085980403717\nn_spray_9: 0.0118164590882\nwpTS: 0.0126984943755\nDewPoint: 0.0137133842036\nn_spray_4: 0.0175262802363\nTmin: 0.0176428634237\nn_spray_1: 0.0176526178006\nn_spray_2: 0.0182206463043\nDepart: 0.0190532862004\nSunset: 0.0201904242953\nSeaLevel: 0.0215213667654\nAvgSpeed: 0.0226120305033\nResultSpeed: 0.0315511106113\nn_spray_5: 0.035795510207\nn_spray_10: 0.0396445530842\nSunrise: 0.0402631568589\nResultDir: 0.0411253737188\nPrecipTotal_cumu: 0.054688485492\nBlock: 0.0777191733988\nTmin_cumu: 0.0780289497288\nSpecies: 0.0810130388833\nTmax_cumu: 0.0814871190718\nTrap: 0.173270528753\n", "name": "stdout", "output_type": "stream"}], "metadata": {"trusted": true, "collapsed": false}, "execution_count": 40, "cell_type": "code", "source": "if __name__ == '__main__':\n    my_model()"}], "nbformat": 4}